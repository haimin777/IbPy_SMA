{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breast density.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haimin777/IbPy_SMA/blob/master/breast_density.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sK1MNcFPrF3e",
        "colab_type": "code",
        "outputId": "5791c463-6f17-40dd-9104-a36d2cc205df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5393g0QuXPd",
        "colab_type": "code",
        "outputId": "aad8582b-dbe9-45eb-c89f-f11c1c52fed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "import os\n",
        "import shutil as sh\n",
        "\n",
        "!pip install pydicom\n",
        "import pydicom as pyd\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "\n",
        "import asyncio\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "from os.path import join\n",
        "\n",
        "import cv2\n",
        "#import my_density_model_tf\n",
        "import numpy as np\n",
        "import pydicom as pyd\n",
        "from keras.models import load_model\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "ROOT_DIR = 'drive/My Drive/M-project/X-dense'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (1.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "378a07bb-88bf-4620-a2ad-cd4e5bd85286",
        "id": "LNZXIbzNbfYS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "if os.path.exists('breast_density_classifier'):\n",
        "  sh.rmtree('breast_density_classifier')\n",
        "  \n",
        "!git clone https://github.com/haimin777/breast_density_classifier.git\n",
        "#os.chdir('breast_density_classifier')  \n",
        "#os.chdir('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'breast_density_classifier'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)   \u001b[K\rremote: Counting objects:  33% (2/6)   \u001b[K\rremote: Counting objects:  50% (3/6)   \u001b[K\rremote: Counting objects:  66% (4/6)   \u001b[K\rremote: Counting objects:  83% (5/6)   \u001b[K\rremote: Counting objects: 100% (6/6)   \u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 56 (delta 1), reused 0 (delta 0), pack-reused 50\u001b[K\n",
            "Unpacking objects: 100% (56/56), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TYyzFLA_MQb9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import breast_density_classifier\n",
        "#sys.path.append(os.path.join(ROOT_DIR, 'breast_density_classifier'))  # To find local version of the library\n",
        "import breast_density_classifier.utils as utils\n",
        "import breast_density_classifier.density_model as density_model\n",
        "import breast_density_classifier.layers_tf as layers_tf\n",
        "import breast_density_classifier.models_tf as models\n",
        "import breast_density_classifier.density_model_tf as d_models\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7N5KIM_XcaeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "60d01d22-f75c-4710-a522-8868deecef09"
      },
      "cell_type": "code",
      "source": [
        "    parameters = dict(\n",
        "        device_type='gpu',\n",
        "        gpu_number=1,\n",
        "        input_size=(2600, 2000),\n",
        "        image_path='images/',\n",
        "        \n",
        "    )\n",
        "  \n",
        "session_config = tf.ConfigProto()\n",
        "session_config.gpu_options.visible_device_list = str(parameters['gpu_number'])  \n",
        "x_L_CC = tf.placeholder(tf.float32,\n",
        "               shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "x_R_CC = tf.placeholder(tf.float32,\n",
        "              shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "x_L_MLO = tf.placeholder(tf.float32,\n",
        "                          shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "x_R_MLO = tf.placeholder(tf.float32,\n",
        "                         shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "x = (x_L_CC, x_R_CC, x_L_MLO, x_R_MLO)  \n",
        "my_model = models.baseline(x, parameters, nodropout_probability=.99)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/breast_density_classifier/layers_tf.py:94: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eu-OIViD51mx",
        "colab_type": "code",
        "outputId": "28a90c52-cbb3-43ab-f6fa-6925dfcc1434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls breast_density_classifier/saved_models/BreastDensity_BaselineBreastModel/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.ckpt.data-00000-of-00001\tmodel.ckpt.index  model.ckpt.meta  model.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RIg6e-tP_bUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = 'histogram'\n",
        "#model = 'cnn'\n",
        " \n",
        "parameters = dict(\n",
        "device_type = 'cpu',\n",
        "gpu_number = 1,\n",
        "input_size = (2600, 2000),\n",
        "image_path = 'images/'\n",
        "\t)\n",
        "    \n",
        "if model == 'histogram':    \n",
        "\t\tparameters['model_class'] = models.BaselineHistogramModel\n",
        "\t\tparameters['bins_histogram'] = 50\n",
        "\t\tparameters['initial_parameters'] = 'saved_models/BreastDensity_BaselineHistogramModel/model.ckpt'\n",
        "        \n",
        "elif model == 'cnn':\n",
        "\t\tparameters['model_class'] = models.BaselineBreastModel \n",
        "\t\tparameters['initial_parameters'] = 'saved_models/BreastDensity_BaselineBreastModel/model.ckpt'\n",
        "\t\t\n",
        "density_model.training(parameters, model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQQwAcrsC6ac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41b7d2e9-e94f-4c73-8fdf-b2d3af0b9e7a"
      },
      "cell_type": "code",
      "source": [
        "#try to make new model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer, Dense, Activation, Conv2D, BatchNormalization, Dropout, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Flatten, AveragePooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "config1 = {'activation': 'softmax',\n",
        " 'activity_regularizer': None,\n",
        " 'bias_constraint': None,\n",
        " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
        " 'bias_regularizer': None,\n",
        " 'kernel_constraint': None,\n",
        " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
        "  'config': {'distribution': 'normal',\n",
        "   'mode': 'fan_in',\n",
        "   'scale': 2.0,\n",
        "   'seed': None}},\n",
        " 'kernel_regularizer': {'class_name': 'L1L2',\n",
        "  'config': {'l1': 0.0, 'l2': 0.009999999776482582}},\n",
        " 'name': 'dense_1',\n",
        " 'trainable': True,\n",
        " 'units': 4,\n",
        " 'use_bias': True}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "279sKSL4OiWy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Conv2D, Add, MaxPool2D, Flatten, Concatenate, AvgPool2D, Dropout\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4nCTgGuOuHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a1 = Input(shape=(2600, 2000, 1))\n",
        "a2 = Input(shape=(2600, 2000, 1))\n",
        "a3 = Input(shape=(2600, 2000, 1))\n",
        "a4 = Input(shape=(2600, 2000, 1))\n",
        "\n",
        "def add_conv(a1, a2, a3, a4, filt_num=32, strides=(2,2)):\n",
        "  out1 = Conv2D(filters=filt_num, kernel_size=(3,3), strides=strides)(a1)\n",
        "  out2 = Conv2D(filters=filt_num, kernel_size=(3,3), strides=strides)(a2)\n",
        "  out3 = Conv2D(filters=filt_num, kernel_size=(3,3), strides=strides)(a3)\n",
        "  out4 = Conv2D(filters=filt_num, kernel_size=(3,3), strides=strides)(a4)\n",
        "  \n",
        "  h = (out1, out2, out3, out4)\n",
        "  return h\n",
        "\n",
        "def add_max_pool(inp_layer, strides=(3,3)):\n",
        "  out1 = MaxPool2D(strides=strides)(inp_layer[0])\n",
        "  out2 = MaxPool2D(strides=strides)(inp_layer[1])\n",
        "  out3 = MaxPool2D(strides=strides)(inp_layer[2])\n",
        "  out4 = MaxPool2D(strides=strides)(inp_layer[3])\n",
        "\n",
        "  \n",
        "  h = (out1, out2, out3, out4)\n",
        "  return h\n",
        "\n",
        "def add_avg_pooling(inp_layer):\n",
        "  input_layer_shape = inp_layer[0].get_shape()\n",
        "  pooling_shape =  (2,2)#[1, input_layer_shape[1], input_layer_shape[2], 1]\n",
        "\n",
        "  out1 = AvgPool2D(pool_size=pooling_shape, strides=pooling_shape)(inp_layer[0])\n",
        "  out2 = AvgPool2D(pool_size=pooling_shape, strides=pooling_shape)(inp_layer[1])\n",
        "  out3 = AvgPool2D(pool_size=pooling_shape, strides=pooling_shape)(inp_layer[2])\n",
        "  out4 = AvgPool2D(pool_size=pooling_shape, strides=pooling_shape)(inp_layer[3])\n",
        "\n",
        "  h = (out1, out2, out3, out4)\n",
        "  return h\n",
        "\n",
        "def add_flatten(inp_layer):\n",
        "  out1 = Flatten()(inp_layer[0])\n",
        "  out2 = Flatten()(inp_layer[1])\n",
        "  out3 = Flatten()(inp_layer[2])\n",
        "  out4 = Flatten()(inp_layer[3])\n",
        "  \n",
        "  h = Concatenate(axis=1)([out1, out2, out3, out4])\n",
        "  return h\n",
        "\n",
        "\n",
        "\n",
        "# 1 conv\n",
        "h = add_conv(a1, a2, a3, a4)\n",
        "\n",
        "# 2 conv\n",
        "\n",
        "h = add_max_pool(h)\n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=64)\n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=64, strides=(1,1)) \n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=64, strides=(1,1)) \n",
        "\n",
        "# 3 conv\n",
        "\n",
        "h = add_max_pool(h, strides=(2,2))\n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=128, strides=(1,1)) \n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=128, strides=(1,1)) \n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=128, strides=(1,1)) \n",
        "\n",
        "# 4 conv\n",
        "\n",
        "h = add_max_pool(h, strides=(2,2))\n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=128, strides=(1,1)) \n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=128, strides=(1,1)) \n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=128, strides=(1,1)) \n",
        "\n",
        "# 5 conv\n",
        "\n",
        "h = add_max_pool(h, strides=(2,2))\n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=256, strides=(1,1)) \n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=256, strides=(1,1)) \n",
        "h = add_conv(h[0], h[1], h[2], h[3], filt_num=256, strides=(1,1)) \n",
        "\n",
        "\n",
        "h = add_avg_pooling(h)\n",
        "h = add_flatten(h)\n",
        "\n",
        "#h = Dense(4*256,activation='relu')(h) \n",
        "h = Dropout(.15)(h)\n",
        "out = Dense(4,activation='softmax')(h) \n",
        "\n",
        "my_model = Model(inputs=[a1,a2,a3, a4], outputs=out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m1vV6HbJexbX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-IXBXrvDd-a",
        "colab_type": "code",
        "outputId": "a3f3c745-9947-4b0d-ecc0-9411c403c5f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#model.add(InputLayer((2600, 2000, 1)))\n",
        "model.add(inp_model([a1, a2, a3]))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), name='conv1'))\n",
        "#second conv\n",
        "model.add(MaxPooling2D(strides=(3,3)))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), name='conv2a'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), name='conv2b'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), name='conv2c'))\n",
        "\n",
        "#3 conv\n",
        "model.add(MaxPooling2D(strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), name='conv3a'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), name='conv3b'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), name='conv3c'))\n",
        "\n",
        "# 4 conv\n",
        "model.add(MaxPooling2D(strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), name='conv4a'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), name='conv4b'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), name='conv4c'))\n",
        "\n",
        "# 5 conv\n",
        "\n",
        "model.add(MaxPooling2D(strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), name='conv5a'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), name='conv5b'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), name='conv5c'))\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Dropout(.97))\n",
        "\n",
        "\n",
        "model.add(AveragePooling2D())\n",
        "#model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "\n",
        "#model.add(Dense(4*256))\n",
        "model.add(Dense.from_config(config1))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d1ca2812b4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.add(InputLayer((2600, 2000, 1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#second conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise TypeError('The added layer must be '\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                             'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: Tensor(\"model_1_1/add_2/add_1:0\", shape=(?, 2600, 2000), dtype=float32)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NX_ZSzQuNgih",
        "colab_type": "code",
        "outputId": "06ff5785-61ee-40cf-a553-b0e80aebfd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "cell_type": "code",
      "source": [
        "inp_model = Model(inputs=[InputLayer((2600, 2000)), InputLayer(2600, 2000)], outputs=)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-471dc0450b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                  'a `batch_input_shape` or an `input_shape`.')\n\u001b[1;32m     68\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QnH8H30NMUzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def isdicom(file_path):\n",
        "    try:\n",
        "        if pyd.dcmread(file_path).ImageType[0] != 'ORIGINAL':\n",
        "            return True\n",
        "        else:\n",
        "            print('RAW image acepted')\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return False\n",
        "        \n",
        "        \n",
        "\n",
        "def load_dcm_images(image_path):\n",
        "    \"\"\"\n",
        "    Function that loads and preprocess input images\n",
        "    :param image_path: base path to image\n",
        "    :param view: L-CC / R-CC / L-MLO / R-MLO\n",
        "    :return: Batch x Height x Width x Channels array\n",
        "    \"\"\"\n",
        "    ds = pyd.dcmread(image_path)\n",
        "    #view = \n",
        "    image = ds.pixel_array\n",
        "    \n",
        "    image = cv2.resize(image, (2000, 2600), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    image = image.astype(np.float32)\n",
        "    utils.normalize_single_image(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = np.expand_dims(image, axis=3)\n",
        "\n",
        "    return image\n",
        "        \n",
        "\n",
        "def inference(parameters, verbose=True):\n",
        "    tf.set_random_seed(7)\n",
        "\n",
        "    with tf.Graph().as_default():\n",
        "        with tf.device('/' + parameters['device_type']):\n",
        "            # initialize input holders\n",
        "            if parameters[\"model_type\"] == 'cnn':\n",
        "                x_l_cc = tf.placeholder(tf.float32,\n",
        "                                        shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "                x_r_cc = tf.placeholder(tf.float32,\n",
        "                                        shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "                x_l_mlo = tf.placeholder(tf.float32,\n",
        "                                         shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "                x_r_mlo = tf.placeholder(tf.float32,\n",
        "                                         shape=[None, parameters['input_size'][0], parameters['input_size'][1], 1])\n",
        "                x = (x_l_cc, x_r_cc, x_l_mlo, x_r_mlo)\n",
        "                model_class = models.BaselineBreastModel\n",
        "            elif parameters[\"model_type\"] == 'histogram':\n",
        "                x = tf.placeholder(tf.float32, shape=[None, parameters['bins_histogram'] * 4])\n",
        "                model_class = models.BaselineHistogramModel\n",
        "            else:\n",
        "                raise RuntimeError(parameters[\"model_type\"])\n",
        "\n",
        "            # holders for dropout and Gaussian noise\n",
        "            nodropout_probability = tf.placeholder(tf.float32, shape=())\n",
        "            gaussian_noise_std = tf.placeholder(tf.float32, shape=())\n",
        "\n",
        "            # construct models\n",
        "            model = model_class(parameters, x, nodropout_probability, gaussian_noise_std)\n",
        "            y_prediction_density = model.y_prediction_density\n",
        "\n",
        "        # allocate computation resources\n",
        "        if parameters['device_type'] == 'gpu':\n",
        "            session_config = tf.ConfigProto()\n",
        "            session_config.gpu_options.visible_device_list = str(parameters['gpu_number'])\n",
        "        elif parameters['device_type'] == 'cpu':\n",
        "            session_config = tf.ConfigProto(device_count={'GPU': 0})\n",
        "        else:\n",
        "            raise RuntimeError(parameters['device_type'])\n",
        "\n",
        "        with tf.Session(config=session_config) as session:\n",
        "            session.run(tf.global_variables_initializer())\n",
        "\n",
        "            # loads the pre-trained parameters if it's provided\n",
        "            density_model_tf.optimistic_restore(session, parameters['model_path'])\n",
        "\n",
        "            # load input images\n",
        "\n",
        "            dcm_paths = [os.path.join(parameters['image_path'], dcm_file) for dcm_file in os.listdir(parameters['image_path']) if\n",
        "                         isdicom(os.path.join(parameters['image_path'], dcm_file))]\n",
        "\n",
        "            datum_l_cc = load_dcm_images(dcm_paths[0])\n",
        "            datum_r_cc = load_dcm_images(dcm_paths[1])\n",
        "            datum_l_mlo = load_dcm_images(dcm_paths[2])\n",
        "            datum_r_mlo = load_dcm_images(dcm_paths[3])\n",
        "\n",
        "            # populate feed_dict for TF session\n",
        "            # No dropout and no gaussian noise in inference\n",
        "            feed_dict_by_model = {nodropout_probability: 1.0, gaussian_noise_std: 0.0}\n",
        "            if parameters[\"model_type\"] == 'cnn':\n",
        "                feed_dict_by_model[x_l_cc] = datum_l_cc\n",
        "                feed_dict_by_model[x_r_cc] = datum_r_cc\n",
        "                feed_dict_by_model[x_l_mlo] = datum_l_mlo\n",
        "                feed_dict_by_model[x_r_mlo] = datum_r_mlo\n",
        "            elif parameters[\"model_type\"] == 'histogram':\n",
        "                feed_dict_by_model[x] = utils.histogram_features_generator(\n",
        "                    #[datum_l_cc, datum_r_cc, datum_l_mlo, datum_r_mlo],\n",
        "                    [datum_r_mlo, datum_l_cc, datum_l_mlo,  datum_r_cc],\n",
        "\n",
        "                    parameters,\n",
        "                )\n",
        "\n",
        "            # run the session for a prediction\n",
        "            prediction_density = session.run(y_prediction_density, feed_dict=feed_dict_by_model)\n",
        "\n",
        "            if verbose:\n",
        "                # nicely prints out the predictions\n",
        "                print('Density prediction:\\n' +\n",
        "                      '\\tAlmost entirely fatty (0):\\t\\t\\t' + str(prediction_density[0, 0]) + '\\n' +\n",
        "                      '\\tScattered areas of fibroglandular density (1):\\t' + str(prediction_density[0, 1]) + '\\n' +\n",
        "                      '\\tHeterogeneously dense (2):\\t\\t\\t' + str(prediction_density[0, 2]) + '\\n' +\n",
        "                      '\\tExtremely dense (3):\\t\\t\\t\\t' + str(prediction_density[0, 3]) + '\\n')\n",
        "\n",
        "            return prediction_density[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aodAQ6hePvL1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/breast_density_classifier')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PKq4G-B4Pvv-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "        'model_type': 'histogram',\n",
        "        'bins_histogram': 50,\n",
        "        'model_path': \"/content/drive/My Drive/M-project/saved_models/BreastDensity_BaselineHistogramModel/model.ckpt\",\n",
        "        'device_type': \"cpu\",\n",
        "        'gpu_number': 0,\n",
        "        # 'image_path': '/home/haimin/PycharmProjects/xray_density/breast_density_classifier/dcm_images'\n",
        "        # 'image_path': glob.glob(folder+'/FD.*/MAMMOGRAM..Screening*')[0]\n",
        "        'image_path': None\n",
        "              }\n",
        "\n",
        "folders = glob.glob('/content/drive/My Drive/M-project/ACR_1/*')\n",
        "print(folders[0])\n",
        "#inference(parameters, verbose=True)\n",
        "\n",
        "for folder in folders:\n",
        "  parameters['image_path'] = folder\n",
        "  inference(parameters, verbose=True)\n",
        "\n",
        "'''\n",
        "for folder in folders:\n",
        "  parameters['image_path'] = folder\n",
        "  try:\n",
        "    inference(parameters, verbose=True)\n",
        "    \n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "''' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_B_k-_KGYdDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JiIv8OS1W0jm",
        "colab_type": "code",
        "outputId": "62a42aef-0d2e-4f8c-9854-671f112229c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "pyd.dcmread(join(folders[1], '20180404142657.104.1978749.dcm'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0008, 0008) Image Type                          CS: ['DERIVED', 'PRIMARY', '', 'RIGHT']\n",
              "(0008, 0016) SOP Class UID                       UI: Secondary Capture Image Storage\n",
              "(0008, 0018) SOP Instance UID                    UI: 1.2.826.0.1.3680043.2.1143.5048753967654858577015913393542830299\n",
              "(0008, 0020) Study Date                          DA: '20190118'\n",
              "(0008, 0023) Content Date                        DA: '20180404'\n",
              "(0008, 0030) Study Time                          TM: '235915'\n",
              "(0008, 0033) Content Time                        TM: '132701'\n",
              "(0008, 0060) Modality                            CS: 'MG'\n",
              "(0020, 000d) Study Instance UID                  UI: 1.2.826.0.1.3680043.2.1143.6431022368119457168403934632901395813\n",
              "(0020, 000e) Series Instance UID                 UI: 1.2.826.0.1.3680043.2.1143.9523496642559791133477039714320579440\n",
              "(0028, 0002) Samples per Pixel                   US: 1\n",
              "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
              "(0028, 0010) Rows                                US: 3506\n",
              "(0028, 0011) Columns                             US: 2800\n",
              "(0028, 0100) Bits Allocated                      US: 16\n",
              "(0028, 0101) Bits Stored                         US: 16\n",
              "(0028, 0102) High Bit                            US: 15\n",
              "(0028, 0103) Pixel Representation                US: 0\n",
              "(7fe0, 0010) Pixel Data                          OW: Array of 19633600 bytes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "21mQ3etrW704",
        "colab_type": "code",
        "outputId": "cfe92edb-a3a6-4ac9-f862-be2c93488f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "        'model_type': 'histogram',\n",
        "        'bins_histogram': 50,\n",
        "        'model_path': \"/content/drive/My Drive/M-project/saved_models/BreastDensity_BaselineHistogramModel/model.ckpt\",\n",
        "        'device_type': \"cpu\",\n",
        "        'gpu_number': 0,\n",
        "        # 'image_path': '/home/haimin/PycharmProjects/xray_density/breast_density_classifier/dcm_images'\n",
        "        # 'image_path': glob.glob(folder+'/FD.*/MAMMOGRAM..Screening*')[0]\n",
        "        'image_path': '/content/drive/My Drive/M-project/ACR_1/63873'\n",
        "              }\n",
        "\n",
        "inference(parameters, verbose=True)\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/M-project/saved_models/BreastDensity_BaselineHistogramModel/model.ckpt\n",
            "Density prediction:\n",
            "\tAlmost entirely fatty (0):\t\t\t0.17023645\n",
            "\tScattered areas of fibroglandular density (1):\t0.78430045\n",
            "\tHeterogeneously dense (2):\t\t\t0.042454615\n",
            "\tExtremely dense (3):\t\t\t\t0.0030084394\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.17023645, 0.78430045, 0.04245462, 0.00300844], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "M-fomYYwYz_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}